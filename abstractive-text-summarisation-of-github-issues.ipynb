{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NLP Project Team 4"},{"metadata":{"_uuid":"77282ca6f97a7740db9f87619452f0a87c03f595","_cell_guid":"a11e8844-b449-4bef-aed7-46687dac4452","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_colwidth', 500)\nfrom sklearn.model_selection import train_test_split\nfrom ktext.preprocess import processor","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"52eee747b23516cb801b5922cd9cc81ebc3731f4","_cell_guid":"617564a3-b52b-4fff-a067-67736855eaa9"},"cell_type":"markdown","source":"# Read Data And Preview\n## To spilt into train and test sets"},{"metadata":{"_uuid":"99be74c506654cbd98fcef466e8c458b1f1026d3","_cell_guid":"6274092b-29bd-4c75-9dea-7206f4fe1fed","trusted":true},"cell_type":"code","source":"traindf, testdf = train_test_split(pd.read_csv('../input/github_issues.csv').sample(n=5000), \n                                   test_size=.10)\ntrain_body_raw = traindf.body.tolist()\ntrain_title_raw = traindf.issue_title.tolist()\ntraindf.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"                                                                            issue_url  \\\n1984273                                       \"https://github.com/Jguer/yay/issues/5\"   \n526962                    \"https://github.com/geodynamics/specfem3d_globe/issues/565\"   \n4287397                                   \"https://github.com/f500/elewant/issues/43\"   \n5129927                        \"https://github.com/IBM-Blockchain/marbles/issues/144\"   \n4095231  \"https://github.com/ksAutotests/CreateValidAndUpdateInvalidTest/issues/2184\"   \n\n                                                                                                                  issue_title  \\\n1984273                                                                  request: equivalent of yaourt's sync option: --build   \n526962   in the adjoint sources arrays, split the time dependent source function from the fixed lagrange interpolation arrays   \n4287397                                                                                                    last 5 added herds   \n5129927                                                                        can we change the ports in docker-compose.yml?   \n4095231                                                                     tutorial page tutorial_firefox.md issue. qa green   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                            body  \n1984273                                                                                                                                                                                                                                                                                            sync options -b, --build build from sources, abs for official packages, or aur if packages is not found. specify this option twice to build all dependencies.  \n526962                                                                                                                                                                                                                                                                                                                                                                   same issue as in 3d_cartesian, see https://github.com/geodynamics/specfem3d/issues/1008  \n4287397                                                                                                                                                                                                                                                                                                                                                                                                  a place to put the last 5 added herds on the front page  \n5129927                                                                            we are trying to run two instance of marbles application on same docker but when we run one marbles application and then we try to run second marbles application it gives the error like port is already used. and when i changed some random port in docker-compose.yml which is available, it fails to create channel. so which ports are available for ca, orderer, peer?  \n4095231  tutorial issue found: https://github.com/ksautotests/createvalidandupdateinvalidtest/blob/master/tutorials/firefox/tutorial_firefox.md https://github.com/ksautotests/createvalidandupdateinvalidtest/blob/master/tutorials/firefox/tutorial_firefox.md contains only invalid tags. your tutorial was not created. the invalid tags listed below were disregarded. please double-check the following tags:\\n- 12345\\n- qwqwqw affected server: qa green  ","text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>issue_url</th>\n      <th>issue_title</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1984273</th>\n      <td>\"https://github.com/Jguer/yay/issues/5\"</td>\n      <td>request: equivalent of yaourt's sync option: --build</td>\n      <td>sync options -b, --build build from sources, abs for official packages, or aur if packages is not found. specify this option twice to build all dependencies.</td>\n    </tr>\n    <tr>\n      <th>526962</th>\n      <td>\"https://github.com/geodynamics/specfem3d_globe/issues/565\"</td>\n      <td>in the adjoint sources arrays, split the time dependent source function from the fixed lagrange interpolation arrays</td>\n      <td>same issue as in 3d_cartesian, see https://github.com/geodynamics/specfem3d/issues/1008</td>\n    </tr>\n    <tr>\n      <th>4287397</th>\n      <td>\"https://github.com/f500/elewant/issues/43\"</td>\n      <td>last 5 added herds</td>\n      <td>a place to put the last 5 added herds on the front page</td>\n    </tr>\n    <tr>\n      <th>5129927</th>\n      <td>\"https://github.com/IBM-Blockchain/marbles/issues/144\"</td>\n      <td>can we change the ports in docker-compose.yml?</td>\n      <td>we are trying to run two instance of marbles application on same docker but when we run one marbles application and then we try to run second marbles application it gives the error like port is already used. and when i changed some random port in docker-compose.yml which is available, it fails to create channel. so which ports are available for ca, orderer, peer?</td>\n    </tr>\n    <tr>\n      <th>4095231</th>\n      <td>\"https://github.com/ksAutotests/CreateValidAndUpdateInvalidTest/issues/2184\"</td>\n      <td>tutorial page tutorial_firefox.md issue. qa green</td>\n      <td>tutorial issue found: https://github.com/ksautotests/createvalidandupdateinvalidtest/blob/master/tutorials/firefox/tutorial_firefox.md https://github.com/ksautotests/createvalidandupdateinvalidtest/blob/master/tutorials/firefox/tutorial_firefox.md contains only invalid tags. your tutorial was not created. the invalid tags listed below were disregarded. please double-check the following tags:\\n- 12345\\n- qwqwqw affected server: qa green</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"404a096f706e71370c8a610635b7c0a5f93dc138","_cell_guid":"0c57efcc-1db4-45c0-93ef-026877e8b611"},"cell_type":"markdown","source":"## Isssue Body and Title are stored in seperate lists using tolist.  The following code shows us the first issue title entry in the list:"},{"metadata":{"_uuid":"5f6b13cd6759e37ce6a83f0f943a8c93cf906a64","_cell_guid":"4959d954-2952-4033-85d9-5daf389c89ed","trusted":true},"cell_type":"code","source":"# Preview what is in this list\ntrain_title_raw[0]","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"\"request: equivalent of yaourt's sync option: --build\""},"metadata":{}}]},{"metadata":{"_uuid":"ccd61e51938f17e9681859976f71a12b0fca0e50","_cell_guid":"f8e524d0-ed7b-46bb-ba38-8b33f5cedb75"},"cell_type":"markdown","source":"## Use `ktext` to pre-process data"},{"metadata":{"_uuid":"d773fec2ced563f35c42b54644e2b01a84baf58c","_cell_guid":"1967292a-1611-46bf-a171-89bf80b94e03","trusted":true},"cell_type":"code","source":"num_encoder_tokens = 1000\nbody_pp = processor(keep_n=num_encoder_tokens, padding_maxlen=50)\ntrain_body_vecs = body_pp.fit_transform(train_body_raw)","execution_count":4,"outputs":[{"output_type":"stream","text":"WARNING:root:....tokenizing data\nWARNING:root:(1/2) done. 5 sec\nWARNING:root:....building corpus\nWARNING:root:(2/2) done. 0 sec\nWARNING:root:Finished parsing 4,500 documents.\nWARNING:root:...fit is finished, beginning transform\nWARNING:root:...padding data\nWARNING:root:done. 0 sec\n","name":"stderr"}]},{"metadata":{"_uuid":"42cb7e0db7a9501e5cae6055db7c7ec01d8136b1","_cell_guid":"2c75a0fc-b262-45e6-b3a9-d65182b551f4"},"cell_type":"markdown","source":"## An example of processed issue bodies"},{"metadata":{"_uuid":"49a378a782f6ee4aabbfe5518f4c942d006c1c15","_cell_guid":"9e56021c-fed6-42b4-b768-afbe5aab5f27","trusted":true},"cell_type":"code","source":"print('\\noriginal string:\\n', train_body_raw[0], '\\n')\nprint('after pre-processing:\\n', train_body_vecs[0], '\\n')","execution_count":5,"outputs":[{"output_type":"stream","text":"\noriginal string:\n sync options -b, --build build from sources, abs for official packages, or aur if packages is not found. specify this option twice to build all dependencies. \n\nafter pre-processing:\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   1 366 224 141 141  23   1   1  13   1 582  28\n   1  20 582   7  19 131 847  11 214   1   3 141  46 684] \n\n","name":"stdout"}]},{"metadata":{"_uuid":"42fbc4f0c32651f0baefd87d2e7050526d4bb4b3","_cell_guid":"0513217d-3ce1-412a-8f76-afe0a98604d0","trusted":true},"cell_type":"code","source":"# Instantiate a text processor for the titles, with some different parameters\n# append_indicators = True appends the tokens '_start_' and '_end_' to each document\n# padding = 'post' means that zero padding is appended to the end of the of the document (default is 'pre')\n\nnum_decoder_tokens=900\ntitle_pp = processor(append_indicators=True, keep_n=num_decoder_tokens, \n                     padding_maxlen=12, padding ='post')\n\n# process the title data\ntrain_title_vecs = title_pp.fit_transform(train_title_raw)","execution_count":6,"outputs":[{"output_type":"stream","text":"WARNING:root:....tokenizing data\nWARNING:root:(1/2) done. 1 sec\nWARNING:root:....building corpus\nWARNING:root:(2/2) done. 0 sec\nWARNING:root:Finished parsing 4,500 documents.\nWARNING:root:...fit is finished, beginning transform\nWARNING:root:...padding data\nWARNING:root:done. 0 sec\n","name":"stderr"}]},{"metadata":{"_uuid":"00414a474ad8c0d3e283c704d30e653b5549e5da","_cell_guid":"4ec20e49-d1e6-40f6-acfa-00e5780dd8ed","trusted":true},"cell_type":"code","source":"max(title_pp.id2token.keys())","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"901"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Create the encoder decoder model"},{"metadata":{"_uuid":"0105ab4ca68e285d66507862fe4a6274b59b0591","_cell_guid":"9c4d8488-ce1a-48a0-a595-3d78dfc07a85","trusted":true},"cell_type":"code","source":"def load_encoder_inputs(vectorized_body):\n    encoder_input_data = vectorized_body\n    doc_length = encoder_input_data.shape[1]\n    print(f'Shape of encoder input: {encoder_input_data.shape}')\n    return encoder_input_data, doc_length\n\n\ndef load_decoder_inputs(vectorized_title):\n    # For Decoder Input, you don't need the last word as that is only for predictionwhen we are training using Teacher Forcing.\n    decoder_input_data = vectorized_title[:, :-1]\n\n    # Decoder Target Data Is Ahead By 1 Time Step From Decoder Input Data (Teacher Forcing)\n    decoder_target_data = vectorized_title[:, 1:]\n\n    print(f'Shape of decoder input: {decoder_input_data.shape}')\n    print(f'Shape of decoder target: {decoder_target_data.shape}')\n    return decoder_input_data, decoder_target_data","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"36379ebefdbccefe0e32d6a4e08e66209016ed92","_cell_guid":"a254d40a-0b1b-475b-89d1-85d955e6806f","trusted":true},"cell_type":"code","source":"import numpy as np\nencoder_input_data, doc_length = load_encoder_inputs(train_body_vecs)\ndecoder_input_data, decoder_target_data = load_decoder_inputs(train_title_vecs)\nnum_encoder_tokens = max(body_pp.id2token.keys()) + 1\nnum_decoder_tokens = max(title_pp.id2token.keys()) + 1","execution_count":9,"outputs":[{"output_type":"stream","text":"Shape of encoder input: (4500, 50)\nShape of decoder input: (4500, 11)\nShape of decoder target: (4500, 11)\n","name":"stdout"}]},{"metadata":{"_uuid":"5a6560ad29713d4f396763c84205ab0ba77195c3","_cell_guid":"aad7fdea-b331-4f28-b472-62127b838324","trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, BatchNormalization\nfrom keras import optimizers","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"e01a2f2122c42f232c60391452c11c26d00f20b3","_cell_guid":"e3c2fd45-6325-484c-87e3-c97146911a62","trusted":true},"cell_type":"code","source":"#setting latent dimensions arbitarily for embedding and hidden units\nlatent_dim = 80\n\n##### Define Model Architecture ######\n\n########################\n#### Encoder Model ####\nencoder_inputs = Input(shape=(doc_length,), name='Encoder-Input')\n\n# Word embeding for encoder (ex: Issue Body)\nx = Embedding(num_encoder_tokens, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\nx = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n\n# We do not need the `encoder_output` just the hidden state.\n_, state_h = GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x)\n\n# Encapsulate the encoder as a separate entity so we can just encode without decoding if we want to.\nencoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n\nseq2seq_encoder_out = encoder_model(encoder_inputs)\n\n########################\n#### Decoder Model ####\ndecoder_inputs = Input(shape=(None,), name='Decoder-Input')  # for teacher forcing\n\n# Word Embedding For Decoder (ex: Issue Titles)\ndec_emb = Embedding(num_decoder_tokens, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\ndec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n\n# Set up the decoder, using `decoder_state_input` as initial state.\ndecoder_gru = GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\ndecoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\nx = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n\n# Dense layer for prediction\ndecoder_dense = Dense(num_decoder_tokens+2, activation='softmax', name='Final-Output-Dense')\n#softmax is a mathematical exponential function to calculate the probability distribution\ndecoder_outputs = decoder_dense(x)\n\n########################\n#### Seq2Seq Model ####\n\nseq2seq_Model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\nseq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy') \n#sparse_categorical_crossentropy is used to calculate probabilistic loss between label and predictions given word embeddimgs","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the model"},{"metadata":{"_uuid":"6ede1ab46b1a0dded0b98baf03a8a6acf0476378","_cell_guid":"c39cee27-88b4-42db-8c95-a679ae0bb024","trusted":true},"cell_type":"code","source":"from keras.callbacks import CSVLogger, ModelCheckpoint\n\nscript_name_base = 'tutorial_seq2seq'\nmodel_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n                                   save_best_only=True)\n\nbatch_size = 100\nepochs = 4\nhistory = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.10, callbacks=[model_checkpoint])","execution_count":12,"outputs":[{"output_type":"stream","text":"Train on 4050 samples, validate on 450 samples\nEpoch 1/4\n4050/4050 [==============================] - 13s 3ms/step - loss: 4.9838 - val_loss: 3.0693\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/Keras-2.1.3-py3.6.egg/keras/engine/topology.py:2364: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model/Encoder-Last-GRU/while/Exit_2:0' shape=(?, 80) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","name":"stderr"},{"output_type":"stream","text":"Epoch 2/4\n4050/4050 [==============================] - 11s 3ms/step - loss: 3.0672 - val_loss: 2.7000\nEpoch 3/4\n4050/4050 [==============================] - 12s 3ms/step - loss: 2.6515 - val_loss: 2.6991\nEpoch 4/4\n4050/4050 [==============================] - 15s 4ms/step - loss: 2.5142 - val_loss: 2.7811\n","name":"stdout"}]},{"metadata":{"_uuid":"1e6acb8c0f8266334a4c1f00256b887787e3fa57","collapsed":true,"_cell_guid":"df1e6ee6-e4da-49fc-bd44-c1bdb1031499"},"cell_type":"markdown","source":"# Inference model"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install annoy\nfrom annoy import AnnoyIndex\nfrom tqdm import tqdm\nimport logging\nimport nltk\nfrom nltk.translate.bleu_score import corpus_bleu","execution_count":125,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: annoy in /opt/conda/lib/python3.6/site-packages\r\n","name":"stdout"}]},{"metadata":{"_uuid":"b1e9dcd5b249f390fe6aab470e55986fcbcf18db","_cell_guid":"287d755e-d8bc-47a2-8b53-d0674750a0ab","trusted":true},"cell_type":"code","source":"def extract_decoder_model(model):\n    \"\"\"\n    Here we extract the decoder from the original model.\n    Inputs: keras model object\n    Outputs: A Keras model object with the following inputs and outputs:\n    Inputs of Keras Model That Is Returned:\n    1: the embedding index for the last predicted word or the <Start> indicator\n    2: the last hidden state\n    Outputs of Keras Model That Is Returned:\n    1.  Prediction (class probabilities) for the next word\n    2.  The hidden state of the decoder, to be fed back into the decoder at the next time step\n    \n    \"\"\"\n    # the latent dimension is the same so we copy it from the decoder output\n    latent_dim = model.get_layer('Decoder-Word-Embedding').output_shape[-1]\n\n    # Reconstruct the input into the decoder\n    decoder_inputs = model.get_layer('Decoder-Input').input\n    dec_emb = model.get_layer('Decoder-Word-Embedding')(decoder_inputs)\n    dec_bn = model.get_layer('Decoder-Batchnorm-1')(dec_emb)\n\n    # Creating a layer for the feedback loop from predictions back into the GRU\n    gru_inference_state_input = Input(shape=(latent_dim,), name='hidden_state_input')\n\n    # Crete a layer to reuse the weights\n    # There are two outputs, 1- is the embedding layer output for the teacher forcing\n    #                        2- is the hidden state\n    gru_out, gru_state_out = model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])\n\n    # Reconstruct dense layers\n    dec_bn2 = model.get_layer('Decoder-Batchnorm-2')(gru_out)\n    dense_out = model.get_layer('Final-Output-Dense')(dec_bn2)\n    decoder_model = Model([decoder_inputs, gru_inference_state_input],\n                          [dense_out, gru_state_out])\n    return decoder_model\n\ndef extract_encoder_model(model):\n    \"\"\"\n    Here we extract the encoder from the original Sequence to Sequence Model.\n    Input:keras model object with body of issue as input\n    Returns: keras model object which is encoding of the issue with the last hidden state\n    \"\"\"\n    encoder_model = model.get_layer('Encoder-Model')\n    return encoder_model","execution_count":93,"outputs":[]},{"metadata":{"_uuid":"4d3714fd03fd908c101868a99b820125641f325b","_cell_guid":"86caa810-c55c-46bb-9737-13dd5e175c9e","trusted":true},"cell_type":"code","source":"class Seq2Seq_Inference(object):\n    def __init__(self,\n                 encoder_preprocessor,\n                 decoder_preprocessor,\n                 seq2seq_model):\n\n        self.pp_body = encoder_preprocessor\n        self.pp_title = decoder_preprocessor\n        self.seq2seq_model = seq2seq_model\n        self.encoder_model = extract_encoder_model(seq2seq_model)\n        self.decoder_model = extract_decoder_model(seq2seq_model)\n        self.default_max_len_title = self.pp_title.padding_maxlen\n        self.nn = None\n        self.rec_df = None\n\n    def generate_issue_title(self,\n                             raw_input_text,\n                             max_len_title=None):\n        \"\"\"\n        To generate a title given the body of an issue usin the seq2seq model .\n        Inputs: The body of the issue text as an input string\n        max_len_title: The maximum length of the title the model will generate\n        \"\"\"\n        if max_len_title is None:\n            max_len_title = self.default_max_len_title\n        # get the encoder's features for the decoder\n        raw_tokenized = self.pp_body.transform([raw_input_text])\n        body_encoding = self.encoder_model.predict(raw_tokenized)\n        # we want to save the encoder's embedding before its updated by decoder to use as an embedding for other tasks.\n        original_body_encoding = body_encoding\n        state_value = np.array(self.pp_title.token2id['_start_']).reshape(1, 1)\n\n        decoded_sentence = []\n        stop_condition = False\n        while not stop_condition:\n            preds, st = self.decoder_model.predict([state_value, body_encoding])\n\n            # We are going to ignore indices 0 (padding) and indices 1 (unknown)\n            # Argmax will return the integer index corresponding to the prediction + 2 since we chopped off first two\n            pred_idx = np.argmax(preds[:, :, 2:]) + 2\n\n            # retrieve word from index prediction\n            pred_word_str = self.pp_title.id2token[pred_idx]\n\n            if pred_word_str == '_end_' or len(decoded_sentence) >= max_len_title:\n                stop_condition = True\n                break\n            decoded_sentence.append(pred_word_str)\n\n            # update the decoder for the next word\n            body_encoding = st\n            state_value = np.array(pred_idx).reshape(1, 1)\n\n        return original_body_encoding, ' '.join(decoded_sentence)\n\n\n    def print_example(self,\n                      i,\n                      body_text,\n                      title_text,\n                      url,\n                      threshold):\n        \"\"\"\n        Prints examples\n        \"\"\"\n        if i:\n            print('\\n\\n==============================================')\n            print(f'============== Example # {i} =================\\n')\n\n        if url:\n            print(url)\n\n        print(f\"Issue Body:\\n {body_text} \\n\")\n\n        if title_text:\n            print(f\"Original Title:\\n {title_text}\")\n\n        emb, gen_title = self.generate_issue_title(body_text)\n        print(f\"\\n****** Machine Generated Title (Prediction) ******:\\n {gen_title}\")\n        \n        if self.nn:\n            # return neighbors and distances\n            n, d = self.nn.get_nns_by_vector(emb.flatten(), n=4,\n                                             include_distances=True)\n            neighbors = n[1:]\n            dist = d[1:]\n\n            if min(dist) <= threshold:\n                cols = ['issue_url', 'issue_title', 'body']\n                dfcopy = self.rec_df.iloc[neighbors][cols].copy(deep=True)\n                dfcopy['dist'] = dist\n                similar_issues_df = dfcopy.query(f'dist <= {threshold}')\n\n                print(\"\\n** Similar Issues (using encoder embedding) **:\\n\")\n                display(similar_issues_df)\n\n\n    def demo_model_predictions(self,\n                               n,\n                               issue_df,\n                               threshold=1):\n        \"\"\"\n        Pick n random Issues and display predictions.\n        Input: n- Number of issues to display from issue_df\n               issue_df- pandas DataFrame that contains two columns: `body` and `issue_title`.\n               threshold- float distance threshold for recommendation of similar issues.\n        Output: Prints the original issue body and the model's prediction.\n        \"\"\"\n        # Extract body and title from DF\n        body_text = issue_df.body.tolist()\n        title_text = issue_df.issue_title.tolist()\n        url = issue_df.issue_url.tolist()\n\n        if (len(body_text)==1):\n            demo_list=[0]\n        else:\n            demo_list = np.random.randint(low=1, high=len(body_text), size=n)\n        for i in demo_list:\n            self.print_example(i,\n                               body_text=body_text[i],\n                               title_text=title_text[i],\n                               url=url[i],\n                               threshold=threshold)\n            \n    def prepare_recommender(self, vectorized_array, original_df):\n        \"\"\"\n        Use the annoy library to build recommender\n        Parameters\n        ----------\n        vectorized_array : List[List[int]]\n            This is the list of list of integers that represents your corpus\n            that is fed into the seq2seq model for training.\n        original_df : pandas.DataFrame\n            This is the original dataframe that has the columns\n            ['issue_url', 'issue_title', 'body']\n        Returns\n        -------\n        annoy.AnnoyIndex  object (see https://github.com/spotify/annoy)\n        \"\"\"\n        self.rec_df = original_df\n        emb = self.encoder_model.predict(x=vectorized_array,\n                                         batch_size=vectorized_array.shape[0]//200)\n\n        f = emb.shape[1]\n        self.nn = AnnoyIndex(f)\n        logging.warning('Adding embeddings')\n        for i in tqdm(range(len(emb))):\n            self.nn.add_item(i, emb[i])\n        logging.warning('Building trees for similarity lookup.')\n        self.nn.build(50)\n        return self.nn\n    \n    def evaluate_model(self, holdout_bodies, holdout_titles):\n        \"\"\"\n        Method for calculating BLEU Score.\n        Parameters\n        ----------\n        holdout_bodies : List[str]\n            These are the issue bodies that we want to summarize\n        holdout_titles : List[str]\n            This is the ground truth we are trying to predict --> issue titles\n        Returns\n        -------\n        bleu : float\n            The BLEU Score\n        \"\"\"\n        actual, predicted = list(), list()\n        assert len(holdout_bodies) == len(holdout_titles)\n        num_examples = len(holdout_bodies)\n\n        logging.warning('Generating predictions.')\n        # step over the whole set TODO: parallelize this\n        for i in tqdm(range(num_examples)):\n            _, yhat = self.generate_issue_title(holdout_bodies[i])\n\n            actual.append(self.pp_title.process_text([holdout_titles[i]])[0])\n            predicted.append(self.pp_title.process_text([yhat])[0])\n        # calculate BLEU score\n        logging.warning('Calculating BLEU.')\n        \n        #must be careful with nltk api for corpus_bleu!, \n        # expects List[List[List[str]]] for ground truth, using List[List[str]] will give you\n        # erroneous results.\n        bleu = corpus_bleu([[a] for a in actual], predicted)\n        return bleu","execution_count":126,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing results"},{"metadata":{"_uuid":"8e85ab7f92c0314d58550b5d87e1b2a93eb6aebe","_cell_guid":"cfc5832e-58ee-4fcc-b3a8-b8f4987e9088","trusted":true},"cell_type":"code","source":"seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=body_pp,\n                                 decoder_preprocessor=title_pp,\n                                 seq2seq_model=seq2seq_Model)","execution_count":127,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"faa84da6a3a560f93fe4d5f4e2965077c985e988","_cell_guid":"40dac3f5-b9b8-4b44-98ee-4c81ba92391d","trusted":true},"cell_type":"code","source":"seq2seq_inf.demo_model_predictions(n=5, issue_df=testdf)","execution_count":84,"outputs":[{"output_type":"stream","text":"\n\n==============================================\n============== Example # 417 =================\n\n\"https://github.com/crscillitoe/dotfiles/issues/1\"\nIssue Body:\n fix your scripts please. it doesn't show pause. and i get line 13 error \n\nOriginal Title:\n can you help me with your polybar\n\n****** Machine Generated Title (Prediction) ******:\n error in the the number\n\n\n==============================================\n============== Example # 493 =================\n\n\"https://github.com/PCMDI/cmor/issues/138\"\nIssue Body:\n congratulations @dnadeau4 on getting this new update! but if i try to install it in uvcdat 2.8.0, it wants to downgrade libnetcdf ... what should i do? force the installation and keep the libnetcdf that's already there? or wait? i don't need cmor right now. it's just that i have started practicing with cmor and i wanted to check what happens if i try to install it $ conda install -n uvcdat-2.8.0 -c conda-forge -c pcmdi -c uvcdat cmor fetching package metadata ............... solving package specifications: . package plan for installation in environment /home/share/unix_files/cdat/miniconda2/envs/uvcdat-2.8.0: the following new packages will be installed: cmor: 3.2.2-np111py27_0 pcmdi the following packages will be downgraded due to dependency conflicts: libnetcdf: 4.4.1.1-2 conda-forge --> 4.4.1-0 conda-forge \n\nOriginal Title:\n conda installation of 3.2.2 in uvcdat 2.8.0 requests a downgrade of libnetcdf\n\n****** Machine Generated Title (Prediction) ******:\n add to the the the same the the same the the same\n\n\n==============================================\n============== Example # 276 =================\n\n\"https://github.com/Chainsawkitten/LargeGameProjectEngine/issues/914\"\nIssue Body:\n add new texture to bucket to make it more noticable. \n\nOriginal Title:\n add new texture to bucket.\n\n****** Machine Generated Title (Prediction) ******:\n add to the the the same the the same the the same\n\n\n==============================================\n============== Example # 27 =================\n\n\"https://github.com/timpalpant/rummy/issues/3\"\nIssue Body:\n currently there is a dumb greedy strategy https://github.com/timpalpant/rummy/blob/master/clients/ai/strategy/greedy.go , but it'd be interesting to develop a better ai player \n\nOriginal Title:\n implement a better ai strategy\n\n****** Machine Generated Title (Prediction) ******:\n add to the the the same the the same the the same\n\n\n==============================================\n============== Example # 477 =================\n\n\"https://github.com/este/este/issues/1411\"\nIssue Body:\n just an idea, but i think we can use inline styles where they are supported, and custom components for stuff like media queries. because este is using own set of components, we can - use mouseenter and mouseleave for anchor where we need underline - custom placeholder for textinput component - etc. almost nothing needs to be prefixed http://shouldiprefix.com/ but because inline styles can't have multiple values, we need isomorphic browser detection and have useragentprovider based on client and server user agent string. let's see. \n\nOriginal Title:\n css in js reloaded\n\n****** Machine Generated Title (Prediction) ******:\n add to add to the the the same the the same the\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdf.head()","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"                                                        issue_url  \\\n4159378        \"https://github.com/L2jBrasil/L2jBrasil/issues/35\"   \n1016984       \"https://github.com/sktivd/collabExample/issues/22\"   \n1641396                \"https://github.com/EmmaEm/Roam/issues/40\"   \n4407984          \"https://github.com/jankammerath/iptvx/issues/1\"   \n1321776  \"https://github.com/AEFeinstein/mtg-familiar/issues/194\"   \n\n                                                       issue_title  \\\n4159378  skill sonic move está funcionando sem o sonic force lvl3.   \n1016984               ex1/ex2과 ex3 숙제 함께 pull request 되어 있는 상황입니다.   \n1641396                                      city page shows posts   \n4407984                              implement sdl window creation   \n1321776                    autocomplete suggestions in text search   \n\n                                                                                                                                                                                                                                                                                                body  \n4159378  descrição/description skill sonic move está funcionando sem o sonic force lvl3. proposta de ajuste opcional / fix proposal optional anexos/ attachments printscreen, links ,etc ! image https://user-images.githubusercontent.com/3593706/32866791-8b2190c8-ca50-11e7-810c-5b3f583ec83f.png  \n1016984                                                                                                                                       ex1/ex2가 master에 merge되지 않은 상태에서 ex3 숙제 내용을 커밋했습니다. 그래서 ex1/ex2 와 ex3가 혼재하고 있는 상황이 되어 버렸네요. 관리자께서 ex1/ex2 merge 후에 ex3 따로 merge 한다고 하셨는데 어떻게 하면 좋을 까요?  \n1641396                                                                                                                                                                                                                                                    view a list of posts on the oakland page.  \n4407984                                                                                                                                                                                                                       creation of an independet sdl window is required to playback a stream.  \n1321776                                                                                                                                                                                autocomplete suggestions should be given in the text search for keywords like flying , prowess and hideaway .  ","text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>issue_url</th>\n      <th>issue_title</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4159378</th>\n      <td>\"https://github.com/L2jBrasil/L2jBrasil/issues/35\"</td>\n      <td>skill sonic move está funcionando sem o sonic force lvl3.</td>\n      <td>descrição/description skill sonic move está funcionando sem o sonic force lvl3. proposta de ajuste opcional / fix proposal optional anexos/ attachments printscreen, links ,etc ! image https://user-images.githubusercontent.com/3593706/32866791-8b2190c8-ca50-11e7-810c-5b3f583ec83f.png</td>\n    </tr>\n    <tr>\n      <th>1016984</th>\n      <td>\"https://github.com/sktivd/collabExample/issues/22\"</td>\n      <td>ex1/ex2과 ex3 숙제 함께 pull request 되어 있는 상황입니다.</td>\n      <td>ex1/ex2가 master에 merge되지 않은 상태에서 ex3 숙제 내용을 커밋했습니다. 그래서 ex1/ex2 와 ex3가 혼재하고 있는 상황이 되어 버렸네요. 관리자께서 ex1/ex2 merge 후에 ex3 따로 merge 한다고 하셨는데 어떻게 하면 좋을 까요?</td>\n    </tr>\n    <tr>\n      <th>1641396</th>\n      <td>\"https://github.com/EmmaEm/Roam/issues/40\"</td>\n      <td>city page shows posts</td>\n      <td>view a list of posts on the oakland page.</td>\n    </tr>\n    <tr>\n      <th>4407984</th>\n      <td>\"https://github.com/jankammerath/iptvx/issues/1\"</td>\n      <td>implement sdl window creation</td>\n      <td>creation of an independet sdl window is required to playback a stream.</td>\n    </tr>\n    <tr>\n      <th>1321776</th>\n      <td>\"https://github.com/AEFeinstein/mtg-familiar/issues/194\"</td>\n      <td>autocomplete suggestions in text search</td>\n      <td>autocomplete suggestions should be given in the text search for keywords like flying , prowess and hideaway .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Custom Input"},{"metadata":{"trusted":true},"cell_type":"code","source":"url='https://github.com/github/hub/issues/2634'\ntitle='React-native cant run on AVD'\nbody='Hi there I recently started working with react native when I started I completely follow the setup docs at https://reactnative.dev/docs/getting-started so after that I tried running the app on an android emulator everything is good I also installed the SDK and have android revision 29 also installed intel 86_64 system image now I got this error also have the environment variables set up even though getting this and im using vs code for devloping'\ndata = [[url, title, body]]\ncustomdf=pd.DataFrame(data, columns = ['issue_url','issue_title', 'body'])\ncustomdf.head()","execution_count":128,"outputs":[{"output_type":"execute_result","execution_count":128,"data":{"text/plain":"                                   issue_url                   issue_title  \\\n0  https://github.com/github/hub/issues/2634  React-native cant run on AVD   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                body  \n0  Hi there I recently started working with react native when I started I completely follow the setup docs at https://reactnative.dev/docs/getting-started so after that I tried running the app on an android emulator everything is good I also installed the SDK and have android revision 29 also installed intel 86_64 system image now I got this error also have the environment variables set up even though getting this and im using vs code for devloping  ","text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>issue_url</th>\n      <th>issue_title</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://github.com/github/hub/issues/2634</td>\n      <td>React-native cant run on AVD</td>\n      <td>Hi there I recently started working with react native when I started I completely follow the setup docs at https://reactnative.dev/docs/getting-started so after that I tried running the app on an android emulator everything is good I also installed the SDK and have android revision 29 also installed intel 86_64 system image now I got this error also have the environment variables set up even though getting this and im using vs code for devloping</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq2seq_inf.demo_model_predictions(n=1, issue_df=customdf)","execution_count":129,"outputs":[{"output_type":"stream","text":"https://github.com/github/hub/issues/2634\nIssue Body:\n Hi there I recently started working with react native when I started I completely follow the setup docs at https://reactnative.dev/docs/getting-started so after that I tried running the app on an android emulator everything is good I also installed the SDK and have android revision 29 also installed intel 86_64 system image now I got this error also have the environment variables set up even though getting this and im using vs code for devloping \n\nOriginal Title:\n React-native cant run on AVD\n\n****** Machine Generated Title (Prediction) ******:\n add to the the same the the same the the same the\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"url='https://github.com/github/hub/issues/2621'\ntitle='Have an option to Choose from one or more github accounts or a login feature and a logout feature '\nbody='I use two GitHub accounts in my system when I do hub create the hub is creating in the repo in my work account. to switch between them I need to remove the hub file and then re-auth. is there a fix for it already?'\ndata = [[url, title, body]]\ncustomdf=pd.DataFrame(data, columns = ['issue_url','issue_title', 'body'])\ncustomdf.head()","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"                                   issue_url  \\\n0  https://github.com/github/hub/issues/2621   \n\n                                                                                          issue_title  \\\n0  Have an option to Choose from one or more github accounts or a login feature and a logout feature    \n\n                                                                                                                                                                                                                    body  \n0  I use two GitHub accounts in my system when I do hub create the hub is creating in the repo in my work account. to switch between them I need to remove the hub file and then re-auth. is there a fix for it already?  ","text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>issue_url</th>\n      <th>issue_title</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://github.com/github/hub/issues/2621</td>\n      <td>Have an option to Choose from one or more github accounts or a login feature and a logout feature</td>\n      <td>I use two GitHub accounts in my system when I do hub create the hub is creating in the repo in my work account. to switch between them I need to remove the hub file and then re-auth. is there a fix for it already?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq2seq_inf.demo_model_predictions(n=1, issue_df=customdf)","execution_count":42,"outputs":[{"output_type":"stream","text":"https://github.com/github/hub/issues/2621\nIssue Body:\n I use two GitHub accounts in my system when I do hub create the hub is creating in the repo in my work account. to switch between them I need to remove the hub file and then re-auth. is there a fix for it already? \n\nOriginal Title:\n Have an option to Choose from one or more github accounts or a login feature and a logout feature \n\n****** Machine Generated Title (Prediction) ******:\n add to the the the same the the same the the same\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Similar titles prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read All 5M data points\nall_data_df = pd.read_csv('../input/github_issues.csv').sample(n=200)\n# Extract the bodies from this dataframe\nall_data_bodies = all_data_df['body'].tolist()\n\n# transform all of the data using the ktext processor\nall_data_vectorized = body_pp.transform_parallel(all_data_bodies)","execution_count":73,"outputs":[{"output_type":"stream","text":"WARNING:root:...tokenizing data\nWARNING:root:...indexing data\nWARNING:root:...padding data\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import dill as dpickle\n# save transformed data\nwith open('all_data_vectorized.dpkl', 'wb') as f:\n    dpickle.dump(all_data_vectorized, f)","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq2seq_inf_rec = Seq2Seq_Inference(encoder_preprocessor=body_pp,\n                                    decoder_preprocessor=title_pp,\n                                    seq2seq_model=seq2seq_Model)\nrecsys_annoyobj = seq2seq_inf_rec.prepare_recommender(all_data_vectorized, all_data_df)","execution_count":130,"outputs":[{"output_type":"stream","text":"WARNING:root:Adding embeddings\n100%|██████████| 200/200 [00:00<00:00, 46694.17it/s]\nWARNING:root:Building trees for similarity lookup.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq2seq_inf_rec.demo_model_predictions(n=1, issue_df=customdf, threshold=1)","execution_count":131,"outputs":[{"output_type":"stream","text":"https://github.com/github/hub/issues/2634\nIssue Body:\n Hi there I recently started working with react native when I started I completely follow the setup docs at https://reactnative.dev/docs/getting-started so after that I tried running the app on an android emulator everything is good I also installed the SDK and have android revision 29 also installed intel 86_64 system image now I got this error also have the environment variables set up even though getting this and im using vs code for devloping \n\nOriginal Title:\n React-native cant run on AVD\n\n****** Machine Generated Title (Prediction) ******:\n add to the the same the the same the the same the\n\n** Similar Issues (using encoder embedding) **:\n\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                                                             issue_url  \\\n3332924                  \"https://github.com/openego/eTraGo/issues/43\"   \n4553562             \"https://github.com/Microsoft/vscode/issues/28268\"   \n521172   \"https://github.com/MarvinTeichmann/tensorflow-fcn/issues/23\"   \n\n                                                                                                issue_title  \\\n3332924                                                                        scaling of line loading plot   \n4553562                                                           why is there no chinese after the update?   \n521172   regarding using this model for my own data set with only two classes, which is of different domain   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        body  \\\n3332924   in my opinion it always leads to confusion when the bar indicating the line loading is scaled differently. what do you think of just strictly scaling it to 0% - 100%? obviously, the plots would often not be that nice and colorful, but that is also a message... ! gurobi_sh_21_ll https://user-images.githubusercontent.com/17782967/30206080-414e1156-948b-11e7-99e9-9eae6175d5b6.png ! gurobi_sh_20_ll https://user-images.githubusercontent.com/17782967/30206115-56fd3f86-948b-11e7-8ce3-a092cdf3afe9.png   \n4553562                                                                                                       - vscode version: code 1.13.0 376c52b955428d205459bea6619fc161fc8faacf, 2017-06-08t16:43:13.058z - os version: windows_nt ia32 10.0.14393 - extensions: |extension|author|version| |---|---|---| |php-intellisense|felixfbecker|1.3.0| |crane|hvyindustries|0.3.6| |phpcomments|yurun|0.0.1|; --- ! image https://user-images.githubusercontent.com/20104656/26956423-1c393e96-4cf0-11e7-9954-0c267fd61db1.png   \n521172   hi marvin, thank you for sharing the code. may i ask you for some advices? i am trying to adopting your code for one of my data set, which has about 300 images with 600 800 sizes. the masked one has about two classes, class 1 takes about 20% of the whole image. the image itself is kind of far away from the data set used to pre-train the vgg model. for instance, the bio-medical data. there are several questions, 1 can i still use the pre-trained vgg weights? 2 which part of the code need i ch...   \n\n             dist  \n3332924  0.489058  \n4553562  0.494118  \n521172   0.497474  ","text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>issue_url</th>\n      <th>issue_title</th>\n      <th>body</th>\n      <th>dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3332924</th>\n      <td>\"https://github.com/openego/eTraGo/issues/43\"</td>\n      <td>scaling of line loading plot</td>\n      <td>in my opinion it always leads to confusion when the bar indicating the line loading is scaled differently. what do you think of just strictly scaling it to 0% - 100%? obviously, the plots would often not be that nice and colorful, but that is also a message... ! gurobi_sh_21_ll https://user-images.githubusercontent.com/17782967/30206080-414e1156-948b-11e7-99e9-9eae6175d5b6.png ! gurobi_sh_20_ll https://user-images.githubusercontent.com/17782967/30206115-56fd3f86-948b-11e7-8ce3-a092cdf3afe9.png</td>\n      <td>0.489058</td>\n    </tr>\n    <tr>\n      <th>4553562</th>\n      <td>\"https://github.com/Microsoft/vscode/issues/28268\"</td>\n      <td>why is there no chinese after the update?</td>\n      <td>- vscode version: code 1.13.0 376c52b955428d205459bea6619fc161fc8faacf, 2017-06-08t16:43:13.058z - os version: windows_nt ia32 10.0.14393 - extensions: |extension|author|version| |---|---|---| |php-intellisense|felixfbecker|1.3.0| |crane|hvyindustries|0.3.6| |phpcomments|yurun|0.0.1|; --- ! image https://user-images.githubusercontent.com/20104656/26956423-1c393e96-4cf0-11e7-9954-0c267fd61db1.png</td>\n      <td>0.494118</td>\n    </tr>\n    <tr>\n      <th>521172</th>\n      <td>\"https://github.com/MarvinTeichmann/tensorflow-fcn/issues/23\"</td>\n      <td>regarding using this model for my own data set with only two classes, which is of different domain</td>\n      <td>hi marvin, thank you for sharing the code. may i ask you for some advices? i am trying to adopting your code for one of my data set, which has about 300 images with 600 800 sizes. the masked one has about two classes, class 1 takes about 20% of the whole image. the image itself is kind of far away from the data set used to pre-train the vgg model. for instance, the bio-medical data. there are several questions, 1 can i still use the pre-trained vgg weights? 2 which part of the code need i ch...</td>\n      <td>0.497474</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# BLEU Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"title='Have an option to Choose from one or more github accounts or a login feature and a logout feature '\nbody='I use two GitHub accounts in my system when I do hub create the hub is creating in the repo in my work account. to switch between them I need to remove the hub file and then re-auth. is there a fix for it already?'\ntitle_list=[title]\nbody_list=[body]","execution_count":115,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq2seq_inf.evaluate_model(holdout_bodies=body_list, holdout_titles = title_list)","execution_count":132,"outputs":[{"output_type":"stream","text":"WARNING:root:Generating predictions.\n100%|██████████| 1/1 [00:00<00:00, 36.29it/s]\nWARNING:root:Calculating BLEU.\n/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","name":"stderr"},{"output_type":"execute_result","execution_count":132,"data":{"text/plain":"0.41266825715677186"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}